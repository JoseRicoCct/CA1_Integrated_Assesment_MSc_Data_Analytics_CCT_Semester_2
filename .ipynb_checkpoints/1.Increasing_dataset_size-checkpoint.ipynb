{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce8e2d98",
   "metadata": {},
   "source": [
    "# Increasing the size of the *people.csv* dataset.\n",
    "\n",
    "## This script will increase *people.csv* file from 235.1MB (0.2295GB) to 1638.4MB (1.6GB), resulting in a new file *people_increased.csv*. The dataset will grow to seven times its original size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "05372622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing needed packages.\n",
    "\n",
    "import time                   # Built-in, no version.\n",
    "import numpy as np            # Version 1.26.4.\n",
    "import pandas as pd           # Version 2.2.1.\n",
    "from datetime import datetime # Built-in, no version."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0da054a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>User Id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Date of birth</th>\n",
       "      <th>Job Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4defE49671cF860</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Shannon</td>\n",
       "      <td>Male</td>\n",
       "      <td>tvang@example.net</td>\n",
       "      <td>574-440-1423x9799</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>Technical brewer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>F89B87bCf8f210b</td>\n",
       "      <td>Regina</td>\n",
       "      <td>Lin</td>\n",
       "      <td>Male</td>\n",
       "      <td>helen14@example.net</td>\n",
       "      <td>001-273-664-2268x90121</td>\n",
       "      <td>1909-06-20</td>\n",
       "      <td>Teacher, adult education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cad6052BDd5DEaf</td>\n",
       "      <td>Pamela</td>\n",
       "      <td>Blake</td>\n",
       "      <td>Female</td>\n",
       "      <td>brent05@example.org</td>\n",
       "      <td>927-880-5785x85266</td>\n",
       "      <td>1964-08-19</td>\n",
       "      <td>Armed forces operational officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>e83E46f80f629CD</td>\n",
       "      <td>Dave</td>\n",
       "      <td>Hoffman</td>\n",
       "      <td>Female</td>\n",
       "      <td>munozcraig@example.org</td>\n",
       "      <td>001-147-429-8340x608</td>\n",
       "      <td>2009-02-19</td>\n",
       "      <td>Ship broker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60AAc4DcaBcE3b6</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Campos</td>\n",
       "      <td>Female</td>\n",
       "      <td>brownevelyn@example.net</td>\n",
       "      <td>166-126-4390</td>\n",
       "      <td>1997-10-02</td>\n",
       "      <td>Media planner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index          User Id First Name Last Name     Sex  \\\n",
       "0      1  4defE49671cF860     Sydney   Shannon    Male   \n",
       "1      2  F89B87bCf8f210b     Regina       Lin    Male   \n",
       "2      3  Cad6052BDd5DEaf     Pamela     Blake  Female   \n",
       "3      4  e83E46f80f629CD       Dave   Hoffman  Female   \n",
       "4      5  60AAc4DcaBcE3b6        Ian    Campos  Female   \n",
       "\n",
       "                     Email                   Phone Date of birth  \\\n",
       "0        tvang@example.net       574-440-1423x9799    2020-07-09   \n",
       "1      helen14@example.net  001-273-664-2268x90121    1909-06-20   \n",
       "2      brent05@example.org      927-880-5785x85266    1964-08-19   \n",
       "3   munozcraig@example.org    001-147-429-8340x608    2009-02-19   \n",
       "4  brownevelyn@example.net            166-126-4390    1997-10-02   \n",
       "\n",
       "                          Job Title  \n",
       "0                  Technical brewer  \n",
       "1          Teacher, adult education  \n",
       "2  Armed forces operational officer  \n",
       "3                       Ship broker  \n",
       "4                     Media planner  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the CSV file into a pandas DataFrame.\n",
    "df = pd.read_csv('people.csv')\n",
    "\n",
    "# Display the first few rows of the DataFrame.\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68e2a45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming columns.\n",
    "\n",
    "df = df.rename(columns={'User Id':'User_Id','First Name':'First_Name','Last Name':'Last_Name',\n",
    "                        'Sex':'Gender','Date of birth': 'DOB','Job Title':'Job_Title'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb9504ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   Index       int64 \n",
      " 1   User_Id     object\n",
      " 2   First_Name  object\n",
      " 3   Last_Name   object\n",
      " 4   Gender      object\n",
      " 5   Email       object\n",
      " 6   Phone       object\n",
      " 7   DOB         object\n",
      " 8   Job_Title   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 137.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Printing out df info.\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6a0a606c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 14000000 entries, 0 to 13999999\n",
      "Data columns (total 9 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   Index       int64 \n",
      " 1   User_Id     object\n",
      " 2   First_Name  object\n",
      " 3   Last_Name   object\n",
      " 4   Gender      object\n",
      " 5   Email       object\n",
      " 6   Phone       object\n",
      " 7   DOB         object\n",
      " 8   Job_Title   object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 961.3+ MB\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time() # Starting time. By timing this operation perfomance is evaluated.\n",
    "\n",
    "def increasing_people_csv(df, target_size):\n",
    "  \n",
    "    original_size = len(df)\n",
    "    additional_copies_needed = target_size // original_size - 1  # Subtract 1 because we already have the original df.\n",
    "    \n",
    "    # Creating a list to hold the original DataFrame and all additional copies needed.\n",
    "    dfs = [df]\n",
    "    \n",
    "    for _ in range(additional_copies_needed):\n",
    "        dfs.append(df.copy())\n",
    "    \n",
    "    # Concatenate all DataFrames in the list to reach the target size.\n",
    "    grown_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # In case the exact multiplication results in a fraction and we need more rows,\n",
    "    # we add the extra rows needed to match the target size.\n",
    "    extra_rows_needed = target_size - len(grown_df)\n",
    "    if extra_rows_needed > 0:\n",
    "        grown_df = pd.concat([grown_df, df.iloc[:extra_rows_needed]], ignore_index=True)\n",
    "    \n",
    "    return grown_df\n",
    "\n",
    "# Here we specify the amount of rows we need.\n",
    "target_size = 14_000_000\n",
    "\n",
    "# Grow the dataset to the exact target size.\n",
    "grown_df = increasing_people_csv(df, target_size)\n",
    "\n",
    "end_time = time.time() # Stopping the clock.\n",
    "\n",
    "df = grown_df.copy()\n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "970bedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time in creating people_increased.csv: 0 minutes 2 seconds\n"
     ]
    }
   ],
   "source": [
    "execution_time = end_time - start_time # Calculating running time.\n",
    "\n",
    "# Convert execution time to minutes and seconds.\n",
    "minutes = int(execution_time // 60)\n",
    "seconds = int(execution_time % 60)\n",
    "\n",
    "print(f\"Running time in creating people_increased.csv: {minutes} minutes {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be919484",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time() # Starting time. By timing this operation perfomance is evaluated.\n",
    "\n",
    "# Printing increased csv file\n",
    "grown_df.to_csv('people_increased.csv', index=False)\n",
    "end_time = time.time()  # Stopping the clock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6134a12b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time in printing out people_increased.csv: 0 minutes 32 seconds\n"
     ]
    }
   ],
   "source": [
    "execution_time = end_time - start_time # Calculating running time.\n",
    "\n",
    "# Convert execution time to minutes and seconds.\n",
    "minutes = int(execution_time // 60)\n",
    "seconds = int(execution_time % 60)\n",
    "\n",
    "print(f\"Running time in printing out people_increased.csv: {minutes} minutes {seconds} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6477b31e",
   "metadata": {},
   "source": [
    "## Why this approach?\n",
    "\n",
    "* ## Store and process a dataset that will crash many known apps, by using the newly created dataset *people_increased.csv*.\n",
    "* ## Given the requirement that all files must be uploaded to `GitHub`, and considering that I have exhausted my `GitHub LFS` *(Large File Storage)* credits, the dataset to be uploaded will be *people.csv*, which is 235.1 MB. Upon compression, it falls below the 100 MB maximum file size limit for `GitHub` uploads."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71897807",
   "metadata": {},
   "source": [
    "Due to the recording requirement and the time constraint of 5 to 7 minutes, I'm setting up a timestamp to show the exact time the script was run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "162b8a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.Increasing_dataset_size.ipynb was last run on: April 05, 2024, 09:35:51\n"
     ]
    }
   ],
   "source": [
    "# Getting current date and time\n",
    "current_time = datetime.now()\n",
    "\n",
    "# Formatting the date and time in a readable format:\n",
    "formatted_time = current_time.strftime('%B %d, %Y, %H:%M:%S')\n",
    "\n",
    "# Print the formatted date and time\n",
    "print(f\"1.Increasing_dataset_size.ipynb was last run on: {formatted_time}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
