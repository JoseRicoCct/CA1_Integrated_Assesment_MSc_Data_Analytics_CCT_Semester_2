{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c4accaf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>User Id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Date of birth</th>\n",
       "      <th>Job Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4defE49671cF860</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Shannon</td>\n",
       "      <td>Male</td>\n",
       "      <td>tvang@example.net</td>\n",
       "      <td>574-440-1423x9799</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>Technical brewer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>F89B87bCf8f210b</td>\n",
       "      <td>Regina</td>\n",
       "      <td>Lin</td>\n",
       "      <td>Male</td>\n",
       "      <td>helen14@example.net</td>\n",
       "      <td>001-273-664-2268x90121</td>\n",
       "      <td>1909-06-20</td>\n",
       "      <td>Teacher, adult education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cad6052BDd5DEaf</td>\n",
       "      <td>Pamela</td>\n",
       "      <td>Blake</td>\n",
       "      <td>Female</td>\n",
       "      <td>brent05@example.org</td>\n",
       "      <td>927-880-5785x85266</td>\n",
       "      <td>1964-08-19</td>\n",
       "      <td>Armed forces operational officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>e83E46f80f629CD</td>\n",
       "      <td>Dave</td>\n",
       "      <td>Hoffman</td>\n",
       "      <td>Female</td>\n",
       "      <td>munozcraig@example.org</td>\n",
       "      <td>001-147-429-8340x608</td>\n",
       "      <td>2009-02-19</td>\n",
       "      <td>Ship broker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60AAc4DcaBcE3b6</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Campos</td>\n",
       "      <td>Female</td>\n",
       "      <td>brownevelyn@example.net</td>\n",
       "      <td>166-126-4390</td>\n",
       "      <td>1997-10-02</td>\n",
       "      <td>Media planner</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index          User Id First Name Last Name     Sex  \\\n",
       "0      1  4defE49671cF860     Sydney   Shannon    Male   \n",
       "1      2  F89B87bCf8f210b     Regina       Lin    Male   \n",
       "2      3  Cad6052BDd5DEaf     Pamela     Blake  Female   \n",
       "3      4  e83E46f80f629CD       Dave   Hoffman  Female   \n",
       "4      5  60AAc4DcaBcE3b6        Ian    Campos  Female   \n",
       "\n",
       "                     Email                   Phone Date of birth  \\\n",
       "0        tvang@example.net       574-440-1423x9799    2020-07-09   \n",
       "1      helen14@example.net  001-273-664-2268x90121    1909-06-20   \n",
       "2      brent05@example.org      927-880-5785x85266    1964-08-19   \n",
       "3   munozcraig@example.org    001-147-429-8340x608    2009-02-19   \n",
       "4  brownevelyn@example.net            166-126-4390    1997-10-02   \n",
       "\n",
       "                          Job Title  \n",
       "0                  Technical brewer  \n",
       "1          Teacher, adult education  \n",
       "2  Armed forces operational officer  \n",
       "3                       Ship broker  \n",
       "4                     Media planner  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "from IPython.utils import io\n",
    "import pandas as pd\n",
    "start_time = time.time()\n",
    "\n",
    "# Replace 'file_path' with the path to your CSV file\n",
    "file_path = \"C:/Users/jose/Downloads/people.csv\"\n",
    "\n",
    "# Read the CSV file into a pandas DataFrame\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f49be8be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 6.712031364440918\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Your data\n",
    "sex = df['Sex']\n",
    "job_titles = df['Job Title']\n",
    "\n",
    "# Encode 'Sex' and 'Job Titles'\n",
    "sex_encoded = [0 if s == 'Male' else 1 for s in sex]\n",
    "label_encoder = LabelEncoder()\n",
    "job_titles_encoded = label_encoder.fit_transform(job_titles)\n",
    "num_unique_job_titles = len(set(job_titles_encoded))\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.tensor(sex_encoded).float().view(-1, 1)\n",
    "y = torch.tensor(job_titles_encoded).long()\n",
    "\n",
    "# Adjusted Neural Network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, num_output_classes):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, num_output_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.log_softmax(self.fc1(x), dim=1)\n",
    "        return x\n",
    "\n",
    "# Instantiate model\n",
    "model = SimpleNN(num_output_classes=num_unique_job_titles)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2dd77603",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 592 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 43\u001b[0m\n\u001b[0;32m     41\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     42\u001b[0m output \u001b[38;5;241m=\u001b[39m model(X)\n\u001b[1;32m---> 43\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(output, y)\n\u001b[0;32m     44\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m     45\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\modules\\loss.py:1179\u001b[0m, in \u001b[0;36mCrossEntropyLoss.forward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor, target: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m-> 1179\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mcross_entropy(\u001b[38;5;28minput\u001b[39m, target, weight\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight,\n\u001b[0;32m   1180\u001b[0m                            ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mignore_index, reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreduction,\n\u001b[0;32m   1181\u001b[0m                            label_smoothing\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlabel_smoothing)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\nn\\functional.py:3059\u001b[0m, in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3057\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size_average \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m reduce \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3058\u001b[0m     reduction \u001b[38;5;241m=\u001b[39m _Reduction\u001b[38;5;241m.\u001b[39mlegacy_get_string(size_average, reduce)\n\u001b[1;32m-> 3059\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_nn\u001b[38;5;241m.\u001b[39mcross_entropy_loss(\u001b[38;5;28minput\u001b[39m, target, weight, _Reduction\u001b[38;5;241m.\u001b[39mget_enum(reduction), ignore_index, label_smoothing)\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 592 is out of bounds."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Preprocessing\n",
    "# Your data\n",
    "sex = df['Sex']\n",
    "job_titles = df['Job Title']\n",
    "\n",
    "# Convert 'Sex' into binary format\n",
    "sex_encoded = [0 if s == 'Male' else 1 for s in sex]  # 0 for Male, 1 for Female\n",
    "\n",
    "# Encode 'Job Title' as integers\n",
    "label_encoder = LabelEncoder()\n",
    "job_titles_encoded = label_encoder.fit_transform(job_titles)\n",
    "\n",
    "# Convert to tensors\n",
    "X = torch.tensor(sex_encoded).float().view(-1, 1)  # Sex as input\n",
    "y = torch.tensor(job_titles_encoded).long()  # Encoded job titles as output\n",
    "\n",
    "# Neural Network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(1, 5)  # 5 units, assuming 5 different job titles in the example\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.log_softmax(self.fc1(x), dim=1)\n",
    "        return x\n",
    "\n",
    "model = SimpleNN()\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(500):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(X)\n",
    "    loss = criterion(output, y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 50 == 0:\n",
    "        print(f'Epoch {epoch}, Loss: {loss.item()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "33177ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jose\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6775 - accuracy: 0.5625\n",
      "Epoch 2/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6644 - accuracy: 0.6875\n",
      "Epoch 3/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6555 - accuracy: 0.7500\n",
      "Epoch 4/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6470 - accuracy: 0.8125\n",
      "Epoch 5/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6387 - accuracy: 0.8750\n",
      "Epoch 6/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.6307 - accuracy: 0.9375\n",
      "Epoch 7/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6231 - accuracy: 0.9375\n",
      "Epoch 8/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6162 - accuracy: 0.9375\n",
      "Epoch 9/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.6087 - accuracy: 0.9375\n",
      "Epoch 10/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.6006 - accuracy: 0.9375\n",
      "Epoch 11/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5931 - accuracy: 0.9375\n",
      "Epoch 12/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5847 - accuracy: 0.9375\n",
      "Epoch 13/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5763 - accuracy: 0.9375\n",
      "Epoch 14/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5683 - accuracy: 0.9375\n",
      "Epoch 15/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.9375\n",
      "Epoch 16/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5495 - accuracy: 0.9375\n",
      "Epoch 17/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.5389 - accuracy: 0.9375\n",
      "Epoch 18/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5275 - accuracy: 0.9375\n",
      "Epoch 19/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5156 - accuracy: 0.9375\n",
      "Epoch 20/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.5049 - accuracy: 0.9375\n",
      "Epoch 21/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4926 - accuracy: 0.9375\n",
      "Epoch 22/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4809 - accuracy: 0.8750\n",
      "Epoch 23/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4686 - accuracy: 0.9375\n",
      "Epoch 24/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.9375\n",
      "Epoch 25/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.4423 - accuracy: 0.9375\n",
      "Epoch 26/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.9375\n",
      "Epoch 27/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.4159 - accuracy: 0.9375\n",
      "Epoch 28/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.4020 - accuracy: 0.9375\n",
      "Epoch 29/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.3897 - accuracy: 0.9375\n",
      "Epoch 30/100\n",
      "4/4 [==============================] - 0s 714us/step - loss: 0.3760 - accuracy: 0.9375\n",
      "Epoch 31/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3630 - accuracy: 0.9375\n",
      "Epoch 32/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.3500 - accuracy: 0.9375\n",
      "Epoch 33/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3362 - accuracy: 0.9375\n",
      "Epoch 34/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3229 - accuracy: 0.9375\n",
      "Epoch 35/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.3091 - accuracy: 0.9375\n",
      "Epoch 36/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.9375\n",
      "Epoch 37/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2880 - accuracy: 0.9375\n",
      "Epoch 38/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2768 - accuracy: 0.9375\n",
      "Epoch 39/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2656 - accuracy: 0.9375\n",
      "Epoch 40/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2566 - accuracy: 0.9375\n",
      "Epoch 41/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2488 - accuracy: 0.9375\n",
      "Epoch 42/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.2402 - accuracy: 0.9375\n",
      "Epoch 43/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2321 - accuracy: 0.9375\n",
      "Epoch 44/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2233 - accuracy: 0.9375\n",
      "Epoch 45/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.2147 - accuracy: 0.9375\n",
      "Epoch 46/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.2069 - accuracy: 0.9375\n",
      "Epoch 47/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1979 - accuracy: 0.9375\n",
      "Epoch 48/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1904 - accuracy: 0.9375\n",
      "Epoch 49/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1863 - accuracy: 0.9375\n",
      "Epoch 50/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1788 - accuracy: 0.9375\n",
      "Epoch 51/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1738 - accuracy: 0.9375\n",
      "Epoch 52/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1683 - accuracy: 0.9375\n",
      "Epoch 53/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1651 - accuracy: 0.9375\n",
      "Epoch 54/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1607 - accuracy: 0.9375\n",
      "Epoch 55/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1569 - accuracy: 0.9375\n",
      "Epoch 56/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1522 - accuracy: 0.9375\n",
      "Epoch 57/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1499 - accuracy: 0.9375\n",
      "Epoch 58/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1471 - accuracy: 0.9375\n",
      "Epoch 59/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1437 - accuracy: 0.9375\n",
      "Epoch 60/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1410 - accuracy: 0.9375\n",
      "Epoch 61/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1390 - accuracy: 0.9375\n",
      "Epoch 62/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1354 - accuracy: 0.9375\n",
      "Epoch 63/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1347 - accuracy: 0.9375\n",
      "Epoch 64/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1315 - accuracy: 0.9375\n",
      "Epoch 65/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1299 - accuracy: 0.9375\n",
      "Epoch 66/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1286 - accuracy: 0.9375\n",
      "Epoch 67/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1259 - accuracy: 0.9375\n",
      "Epoch 68/100\n",
      "4/4 [==============================] - 0s 480us/step - loss: 0.1245 - accuracy: 0.9375\n",
      "Epoch 69/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1216 - accuracy: 0.9375\n",
      "Epoch 70/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1199 - accuracy: 0.9375\n",
      "Epoch 71/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1181 - accuracy: 0.9375\n",
      "Epoch 72/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1160 - accuracy: 0.9375\n",
      "Epoch 73/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1140 - accuracy: 0.9375\n",
      "Epoch 74/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1125 - accuracy: 0.9375\n",
      "Epoch 75/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1088 - accuracy: 0.9375\n",
      "Epoch 76/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1136 - accuracy: 0.9375\n",
      "Epoch 77/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1107 - accuracy: 0.9375\n",
      "Epoch 78/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1082 - accuracy: 0.9375\n",
      "Epoch 79/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1072 - accuracy: 0.9375\n",
      "Epoch 80/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1086 - accuracy: 0.9375\n",
      "Epoch 81/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1060 - accuracy: 0.9375\n",
      "Epoch 82/100\n",
      "4/4 [==============================] - 0s 165us/step - loss: 0.1068 - accuracy: 0.9375\n",
      "Epoch 83/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.1054 - accuracy: 0.9375\n",
      "Epoch 84/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1052 - accuracy: 0.9375\n",
      "Epoch 85/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1047 - accuracy: 0.9375\n",
      "Epoch 86/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1044 - accuracy: 0.9375\n",
      "Epoch 87/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1035 - accuracy: 0.9375\n",
      "Epoch 88/100\n",
      "4/4 [==============================] - 0s 3ms/step - loss: 0.1026 - accuracy: 0.9375\n",
      "Epoch 89/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1025 - accuracy: 0.9375\n",
      "Epoch 90/100\n",
      "4/4 [==============================] - 0s 6ms/step - loss: 0.1019 - accuracy: 0.9375\n",
      "Epoch 91/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1015 - accuracy: 0.9375\n",
      "Epoch 92/100\n",
      "4/4 [==============================] - 0s 834us/step - loss: 0.1040 - accuracy: 0.9375\n",
      "Epoch 93/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1014 - accuracy: 0.9375\n",
      "Epoch 94/100\n",
      "4/4 [==============================] - 0s 1ms/step - loss: 0.1018 - accuracy: 0.9375\n",
      "Epoch 95/100\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 0.1024 - accuracy: 0.9375\n",
      "Epoch 96/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.1010 - accuracy: 0.9375\n",
      "Epoch 97/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.1011 - accuracy: 0.9375\n",
      "Epoch 98/100\n",
      "4/4 [==============================] - 0s 2ms/step - loss: 0.0994 - accuracy: 0.9375\n",
      "Epoch 99/100\n",
      "4/4 [==============================] - 0s 0s/step - loss: 0.0993 - accuracy: 0.9375\n",
      "Epoch 100/100\n",
      "4/4 [==============================] - 0s 5ms/step - loss: 0.0978 - accuracy: 0.9375\n",
      "Test Loss: 1.0892, Test Accuracy: 0.2500\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    \"Sex\": [\"Male\", \"Male\", \"Female\", \"Female\", \"Female\", \"Male\", \"Female\", \"Male\",\n",
    "            \"Female\", \"Male\", \"Male\", \"Female\", \"Female\", \"Female\", \"Male\", \"Male\",\n",
    "            \"Male\", \"Female\", \"Male\", \"Female\"],\n",
    "    \"Job Title\": [\"Technical brewer\", \"Teacher, adult education\", \"Armed forces operational officer\", \"Ship broker\",\n",
    "                  \"Media planner\", \"Engineer, materials\", \"Historic buildings inspector/conservation officer\", \"Engineer, mining\",\n",
    "                  \"Wellsite geologist\", \"Graphic designer\", \"Engineer, water\", \"Product manager\",\n",
    "                  \"Web designer\", \"Homeopath\", \"Scientist, audiological\", \"Manufacturing systems engineer\",\n",
    "                  \"Race relations officer\", \"Administrator\", \"Armed forces operational officer\", \"Psychologist, counselling\"]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Encoding \"Sex\" as binary values\n",
    "encoder = LabelEncoder()\n",
    "df['Sex'] = encoder.fit_transform(df['Sex'])  # Male will be 1, Female will be 0\n",
    "\n",
    "# One-hot encoding \"Job Title\"\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "job_title_encoded = onehot_encoder.fit_transform(df['Job Title'].values.reshape(-1, 1))\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(job_title_encoded, df['Sex'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=5, verbose=1)\n",
    "\n",
    "# Evaluating the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "493b3fec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8900863c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2000000 entries, 0 to 1999999\n",
      "Data columns (total 9 columns):\n",
      " #   Column         Dtype \n",
      "---  ------         ----- \n",
      " 0   Index          int64 \n",
      " 1   User Id        object\n",
      " 2   First Name     object\n",
      " 3   Last Name      object\n",
      " 4   Sex            object\n",
      " 5   Email          object\n",
      " 6   Phone          object\n",
      " 7   Date of birth  object\n",
      " 8   Job Title      object\n",
      "dtypes: int64(1), object(8)\n",
      "memory usage: 137.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1b5153bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Female': 1000505, 'Male': 999495}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def count_genders(df, gender_column='Sex'):\n",
    "    \"\"\"\n",
    "    Count the number of males and females in a pandas DataFrame.\n",
    "\n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): The DataFrame containing the gender data.\n",
    "    gender_column (str): The name of the column containing gender information.\n",
    "\n",
    "    Returns:\n",
    "    dict: A dictionary with counts for 'Male' and 'Female'.\n",
    "    \"\"\"\n",
    "    gender_counts = df[gender_column].value_counts()\n",
    "    return gender_counts.to_dict()\n",
    "\n",
    "# Assuming 'df' is your DataFrame\n",
    "# Here's how you would use the function:\n",
    "gender_counts = count_genders(df)\n",
    "print(gender_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e32661ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>User Id</th>\n",
       "      <th>First Name</th>\n",
       "      <th>Last Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Email</th>\n",
       "      <th>Phone</th>\n",
       "      <th>Date of birth</th>\n",
       "      <th>Job Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4defE49671cF860</td>\n",
       "      <td>Sydney</td>\n",
       "      <td>Shannon</td>\n",
       "      <td>Male</td>\n",
       "      <td>tvang@example.net</td>\n",
       "      <td>574-440-1423x9799</td>\n",
       "      <td>2020-07-09</td>\n",
       "      <td>Technical brewer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>F89B87bCf8f210b</td>\n",
       "      <td>Regina</td>\n",
       "      <td>Lin</td>\n",
       "      <td>Male</td>\n",
       "      <td>helen14@example.net</td>\n",
       "      <td>001-273-664-2268x90121</td>\n",
       "      <td>1909-06-20</td>\n",
       "      <td>Teacher, adult education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Cad6052BDd5DEaf</td>\n",
       "      <td>Pamela</td>\n",
       "      <td>Blake</td>\n",
       "      <td>Female</td>\n",
       "      <td>brent05@example.org</td>\n",
       "      <td>927-880-5785x85266</td>\n",
       "      <td>1964-08-19</td>\n",
       "      <td>Armed forces operational officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>e83E46f80f629CD</td>\n",
       "      <td>Dave</td>\n",
       "      <td>Hoffman</td>\n",
       "      <td>Female</td>\n",
       "      <td>munozcraig@example.org</td>\n",
       "      <td>001-147-429-8340x608</td>\n",
       "      <td>2009-02-19</td>\n",
       "      <td>Ship broker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>60AAc4DcaBcE3b6</td>\n",
       "      <td>Ian</td>\n",
       "      <td>Campos</td>\n",
       "      <td>Female</td>\n",
       "      <td>brownevelyn@example.net</td>\n",
       "      <td>166-126-4390</td>\n",
       "      <td>1997-10-02</td>\n",
       "      <td>Media planner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>7ACb92d81A42fdf</td>\n",
       "      <td>Valerie</td>\n",
       "      <td>Patel</td>\n",
       "      <td>Male</td>\n",
       "      <td>muellerjoel@example.net</td>\n",
       "      <td>001-379-612-1298x853</td>\n",
       "      <td>2021-04-07</td>\n",
       "      <td>Engineer, materials</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>A00bacC18101d37</td>\n",
       "      <td>Dan</td>\n",
       "      <td>Castillo</td>\n",
       "      <td>Female</td>\n",
       "      <td>billmoody@example.net</td>\n",
       "      <td>(448)494-0852x63243</td>\n",
       "      <td>1975-04-09</td>\n",
       "      <td>Historic buildings inspector/conservation officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>B012698Cf31cfec</td>\n",
       "      <td>Clinton</td>\n",
       "      <td>Cochran</td>\n",
       "      <td>Male</td>\n",
       "      <td>glenn94@example.org</td>\n",
       "      <td>4425100065</td>\n",
       "      <td>1966-07-19</td>\n",
       "      <td>Engineer, mining</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>a5bd11BD7dA1a4B</td>\n",
       "      <td>Gabriella</td>\n",
       "      <td>Richard</td>\n",
       "      <td>Female</td>\n",
       "      <td>blane@example.org</td>\n",
       "      <td>352.362.4148x8344</td>\n",
       "      <td>2021-09-02</td>\n",
       "      <td>Wellsite geologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>9540a6df05eF6cf</td>\n",
       "      <td>James</td>\n",
       "      <td>Bailey</td>\n",
       "      <td>Male</td>\n",
       "      <td>pittmanterrence@example.com</td>\n",
       "      <td>(629)632-4570x1832</td>\n",
       "      <td>1963-05-13</td>\n",
       "      <td>Graphic designer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>f967B4EcdF6B227</td>\n",
       "      <td>Shelby</td>\n",
       "      <td>Norton</td>\n",
       "      <td>Male</td>\n",
       "      <td>acannon@example.net</td>\n",
       "      <td>(164)034-4347x22022</td>\n",
       "      <td>2009-08-19</td>\n",
       "      <td>Engineer, water</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>326C83BbeC1BCFd</td>\n",
       "      <td>Jennifer</td>\n",
       "      <td>Lara</td>\n",
       "      <td>Female</td>\n",
       "      <td>davilacassidy@example.org</td>\n",
       "      <td>+1-915-351-2636x083</td>\n",
       "      <td>1962-03-29</td>\n",
       "      <td>Product manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>d9dfB09F01e16EB</td>\n",
       "      <td>Howard</td>\n",
       "      <td>Sanders</td>\n",
       "      <td>Female</td>\n",
       "      <td>brucejoanna@example.org</td>\n",
       "      <td>001-931-852-5157x31682</td>\n",
       "      <td>1912-07-12</td>\n",
       "      <td>Web designer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>1E5b00F6AC95FD8</td>\n",
       "      <td>Stefanie</td>\n",
       "      <td>Dorsey</td>\n",
       "      <td>Female</td>\n",
       "      <td>xcrane@example.net</td>\n",
       "      <td>266-633-2107</td>\n",
       "      <td>1988-04-19</td>\n",
       "      <td>Homeopath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>1cfc2eDd75cfB01</td>\n",
       "      <td>Wyatt</td>\n",
       "      <td>Ali</td>\n",
       "      <td>Male</td>\n",
       "      <td>lawrenceluke@example.org</td>\n",
       "      <td>+1-204-855-1654x3158</td>\n",
       "      <td>1952-04-16</td>\n",
       "      <td>Scientist, audiological</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>c85FcEDF4D7dCA5</td>\n",
       "      <td>Jasmine</td>\n",
       "      <td>Wheeler</td>\n",
       "      <td>Male</td>\n",
       "      <td>xmontgomery@example.com</td>\n",
       "      <td>044-808-5012x5663</td>\n",
       "      <td>1912-08-13</td>\n",
       "      <td>Manufacturing systems engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>AD2Cd35dCaeD2AB</td>\n",
       "      <td>Arthur</td>\n",
       "      <td>Hart</td>\n",
       "      <td>Male</td>\n",
       "      <td>blittle@example.net</td>\n",
       "      <td>712-978-1974x94056</td>\n",
       "      <td>1939-02-16</td>\n",
       "      <td>Race relations officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Ca217c22e3fEf2c</td>\n",
       "      <td>Brandy</td>\n",
       "      <td>Shepherd</td>\n",
       "      <td>Female</td>\n",
       "      <td>ralph98@example.com</td>\n",
       "      <td>+1-324-844-1260x27820</td>\n",
       "      <td>1911-08-29</td>\n",
       "      <td>Administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>DDFea9C0D3b8Bda</td>\n",
       "      <td>Leon</td>\n",
       "      <td>Todd</td>\n",
       "      <td>Male</td>\n",
       "      <td>zhenderson@example.net</td>\n",
       "      <td>664-084-9864x4425</td>\n",
       "      <td>2011-12-24</td>\n",
       "      <td>Armed forces operational officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>eeed253bcc5d02F</td>\n",
       "      <td>Stacey</td>\n",
       "      <td>Skinner</td>\n",
       "      <td>Female</td>\n",
       "      <td>paula37@example.com</td>\n",
       "      <td>026-376-9429x6935</td>\n",
       "      <td>1916-10-15</td>\n",
       "      <td>Psychologist, counselling</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Index          User Id First Name Last Name     Sex  \\\n",
       "0       1  4defE49671cF860     Sydney   Shannon    Male   \n",
       "1       2  F89B87bCf8f210b     Regina       Lin    Male   \n",
       "2       3  Cad6052BDd5DEaf     Pamela     Blake  Female   \n",
       "3       4  e83E46f80f629CD       Dave   Hoffman  Female   \n",
       "4       5  60AAc4DcaBcE3b6        Ian    Campos  Female   \n",
       "5       6  7ACb92d81A42fdf    Valerie     Patel    Male   \n",
       "6       7  A00bacC18101d37        Dan  Castillo  Female   \n",
       "7       8  B012698Cf31cfec    Clinton   Cochran    Male   \n",
       "8       9  a5bd11BD7dA1a4B  Gabriella   Richard  Female   \n",
       "9      10  9540a6df05eF6cf      James    Bailey    Male   \n",
       "10     11  f967B4EcdF6B227     Shelby    Norton    Male   \n",
       "11     12  326C83BbeC1BCFd   Jennifer      Lara  Female   \n",
       "12     13  d9dfB09F01e16EB     Howard   Sanders  Female   \n",
       "13     14  1E5b00F6AC95FD8   Stefanie    Dorsey  Female   \n",
       "14     15  1cfc2eDd75cfB01      Wyatt       Ali    Male   \n",
       "15     16  c85FcEDF4D7dCA5    Jasmine   Wheeler    Male   \n",
       "16     17  AD2Cd35dCaeD2AB     Arthur      Hart    Male   \n",
       "17     18  Ca217c22e3fEf2c     Brandy  Shepherd  Female   \n",
       "18     19  DDFea9C0D3b8Bda       Leon      Todd    Male   \n",
       "19     20  eeed253bcc5d02F     Stacey   Skinner  Female   \n",
       "\n",
       "                          Email                   Phone Date of birth  \\\n",
       "0             tvang@example.net       574-440-1423x9799    2020-07-09   \n",
       "1           helen14@example.net  001-273-664-2268x90121    1909-06-20   \n",
       "2           brent05@example.org      927-880-5785x85266    1964-08-19   \n",
       "3        munozcraig@example.org    001-147-429-8340x608    2009-02-19   \n",
       "4       brownevelyn@example.net            166-126-4390    1997-10-02   \n",
       "5       muellerjoel@example.net    001-379-612-1298x853    2021-04-07   \n",
       "6         billmoody@example.net     (448)494-0852x63243    1975-04-09   \n",
       "7           glenn94@example.org              4425100065    1966-07-19   \n",
       "8             blane@example.org       352.362.4148x8344    2021-09-02   \n",
       "9   pittmanterrence@example.com      (629)632-4570x1832    1963-05-13   \n",
       "10          acannon@example.net     (164)034-4347x22022    2009-08-19   \n",
       "11    davilacassidy@example.org     +1-915-351-2636x083    1962-03-29   \n",
       "12      brucejoanna@example.org  001-931-852-5157x31682    1912-07-12   \n",
       "13           xcrane@example.net            266-633-2107    1988-04-19   \n",
       "14     lawrenceluke@example.org    +1-204-855-1654x3158    1952-04-16   \n",
       "15      xmontgomery@example.com       044-808-5012x5663    1912-08-13   \n",
       "16          blittle@example.net      712-978-1974x94056    1939-02-16   \n",
       "17          ralph98@example.com   +1-324-844-1260x27820    1911-08-29   \n",
       "18       zhenderson@example.net       664-084-9864x4425    2011-12-24   \n",
       "19          paula37@example.com       026-376-9429x6935    1916-10-15   \n",
       "\n",
       "                                            Job Title  \n",
       "0                                    Technical brewer  \n",
       "1                            Teacher, adult education  \n",
       "2                    Armed forces operational officer  \n",
       "3                                         Ship broker  \n",
       "4                                       Media planner  \n",
       "5                                 Engineer, materials  \n",
       "6   Historic buildings inspector/conservation officer  \n",
       "7                                    Engineer, mining  \n",
       "8                                  Wellsite geologist  \n",
       "9                                    Graphic designer  \n",
       "10                                    Engineer, water  \n",
       "11                                    Product manager  \n",
       "12                                       Web designer  \n",
       "13                                          Homeopath  \n",
       "14                            Scientist, audiological  \n",
       "15                     Manufacturing systems engineer  \n",
       "16                             Race relations officer  \n",
       "17                                      Administrator  \n",
       "18                   Armed forces operational officer  \n",
       "19                          Psychologist, counselling  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c8d2fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jose\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "320000/320000 [==============================] - 364s 1ms/step - loss: 0.6932 - accuracy: 0.4995\n",
      "Epoch 2/100\n",
      "320000/320000 [==============================] - 420s 1ms/step - loss: 0.6933 - accuracy: 0.5006\n",
      "Epoch 3/100\n",
      "211688/320000 [==================>...........] - ETA: 2:05 - loss: 0.6931 - accuracy: 0.4996"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m model\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Training the model\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Evaluating the model\u001b[39;00m\n\u001b[0;32m     32\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mevaluate(X_test, y_test, verbose\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\training.py:1788\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1786\u001b[0m \u001b[38;5;66;03m# No error, now safe to assign to logs.\u001b[39;00m\n\u001b[0;32m   1787\u001b[0m logs \u001b[38;5;241m=\u001b[39m tmp_logs\n\u001b[1;32m-> 1788\u001b[0m end_step \u001b[38;5;241m=\u001b[39m step \u001b[38;5;241m+\u001b[39m data_handler\u001b[38;5;241m.\u001b[39mstep_increment\n\u001b[0;32m   1789\u001b[0m callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(end_step, logs)\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\keras\\src\\engine\\data_adapter.py:1431\u001b[0m, in \u001b[0;36mDataHandler.step_increment\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1428\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_step \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m steps_remaining\n\u001b[0;32m   1429\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_steps_per_execution\u001b[38;5;241m.\u001b[39massign(original_spe)\n\u001b[1;32m-> 1431\u001b[0m \u001b[38;5;129m@property\u001b[39m\n\u001b[0;32m   1432\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_increment\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1433\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"The number to increment the step for `on_batch_end` methods.\"\"\"\u001b[39;00m\n\u001b[0;32m   1434\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_step_increment\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Encoding \"Sex\" as binary values\n",
    "encoder = LabelEncoder()\n",
    "df['Sex'] = encoder.fit_transform(df['Sex'])  # Male will be 1, Female will be 0\n",
    "\n",
    "# One-hot encoding \"Job Title\"\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "job_title_encoded = onehot_encoder.fit_transform(df['Job Title'].values.reshape(-1, 1))\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(job_title_encoded, df['Sex'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=5, verbose=1)\n",
    "\n",
    "# Evaluating the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4e5e3a1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "5334/5334 [==============================] - 15s 3ms/step - loss: -3021.6252 - accuracy: 0.0016 - val_loss: -4849.8218 - val_accuracy: 0.0015\n",
      "Epoch 2/10\n",
      "5334/5334 [==============================] - 14s 3ms/step - loss: -4624.6865 - accuracy: 0.0016 - val_loss: -4849.8218 - val_accuracy: 0.0015\n",
      "Epoch 3/10\n",
      "5334/5334 [==============================] - 15s 3ms/step - loss: -4803.5596 - accuracy: 0.0016 - val_loss: -4849.8218 - val_accuracy: 0.0015\n",
      "Epoch 4/10\n",
      "5334/5334 [==============================] - 15s 3ms/step - loss: -4838.9014 - accuracy: 0.0016 - val_loss: -4849.8218 - val_accuracy: 0.0015\n",
      "Epoch 5/10\n",
      "5334/5334 [==============================] - 16s 3ms/step - loss: -4844.9570 - accuracy: 0.0016 - val_loss: -4849.8218 - val_accuracy: 0.0015\n",
      "Epoch 6/10\n",
      "5334/5334 [==============================] - 17s 3ms/step - loss: -4847.1074 - accuracy: 0.0016 - val_loss: -4849.8218 - val_accuracy: 0.0015\n",
      "Epoch 7/10\n",
      "5334/5334 [==============================] - 18s 3ms/step - loss: -4847.6489 - accuracy: 0.0016 - val_loss: -4849.8218 - val_accuracy: 0.0015\n",
      "Epoch 8/10\n",
      "5334/5334 [==============================] - 18s 3ms/step - loss: -4847.9312 - accuracy: 0.0016 - val_loss: -4849.8218 - val_accuracy: 0.0015\n",
      "Epoch 9/10\n",
      "5334/5334 [==============================] - 15s 3ms/step - loss: -4847.9453 - accuracy: 0.0016 - val_loss: -4849.8218 - val_accuracy: 0.0015\n",
      "Epoch 10/10\n",
      "5334/5334 [==============================] - 15s 3ms/step - loss: -4848.0205 - accuracy: 0.0016 - val_loss: -4849.8218 - val_accuracy: 0.0015\n",
      "12500/12500 [==============================] - 12s 926us/step - loss: -4849.8154 - accuracy: 0.0015\n",
      "Test Loss: -4849.8154, Test Accuracy: 0.0015\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load your data into 'df'\n",
    "\n",
    "# Encode 'Sex' as a binary variable\n",
    "sex_encoder = LabelEncoder()\n",
    "df['Sex'] = sex_encoder.fit_transform(df['Sex'])  # Male will be 1, Female will be 0\n",
    "\n",
    "# Encode 'Job Title' with integers\n",
    "job_title_encoder = LabelEncoder()\n",
    "df['Job Title Encoded'] = job_title_encoder.fit_transform(df['Job Title'])\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(df[['Job Title Encoded']], df['Sex'], test_size=0.2, random_state=45)\n",
    "\n",
    "# Parameters\n",
    "input_dim = df['Job Title Encoded'].max() + 1  # Add 1 because index starts from 0\n",
    "embedding_dim = 100  # You can tune this\n",
    "\n",
    "# Neural network with an embedding layer\n",
    "sex_input = Input(shape=(1,), name='sex_input')\n",
    "sex_embedding = Embedding(input_dim=input_dim, output_dim=embedding_dim, name='x_embedding')(job_title_input)\n",
    "sex_vec = Flatten(name='flatten_sex')(sex_embedding)\n",
    "\n",
    "# Hidden layers\n",
    "hidden = Dense(64, activation='sigmoid')(sex_vec)\n",
    "hidden = Dropout(0.2)(hidden)  # Add dropout for regularization\n",
    "hidden = Dense(32, activation='sigmoid')(hidden)\n",
    "hidden = Dropout(0.2)(hidden)\n",
    "hidden = Dense(16, activation='sigmoid')(hidden)\n",
    "hidden = Dropout(0.2)(hidden)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1, activation='relu')(hidden)\n",
    "\n",
    "# Create and compile model\n",
    "model = Model(inputs=job_title_input, outputs=output)\n",
    "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=300, validation_data=(X_test, y_test), verbose=1)  # Fewer epochs for quicker convergence\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "1ff25ce8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jose\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:972: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.52 GiB for an array with shape (2000000, 639) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# One-hot encoding \"Job Title\"\u001b[39;00m\n\u001b[0;32m     13\u001b[0m onehot_encoder \u001b[38;5;241m=\u001b[39m OneHotEncoder(sparse\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m---> 14\u001b[0m job_title_encoded \u001b[38;5;241m=\u001b[39m onehot_encoder\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mJob Title\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Splitting the dataset\u001b[39;00m\n\u001b[0;32m     17\u001b[0m X_train, X_test, y_train, y_test \u001b[38;5;241m=\u001b[39m train_test_split(job_title_encoded, df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSex\u001b[39m\u001b[38;5;124m'\u001b[39m], test_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, random_state\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m42\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:915\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    911\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[0;32m    912\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[1;32m--> 915\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[0;32m    916\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    917\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[0;32m    918\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\_set_output.py:140\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[1;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[0;32m    139\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m--> 140\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    141\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    142\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[0;32m    143\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    144\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m    145\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[0;32m    146\u001b[0m         )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:1056\u001b[0m, in \u001b[0;36mOneHotEncoder.transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1050\u001b[0m out \u001b[38;5;241m=\u001b[39m sparse\u001b[38;5;241m.\u001b[39mcsr_matrix(\n\u001b[0;32m   1051\u001b[0m     (data, indices, indptr),\n\u001b[0;32m   1052\u001b[0m     shape\u001b[38;5;241m=\u001b[39m(n_samples, feature_indices[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]),\n\u001b[0;32m   1053\u001b[0m     dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype,\n\u001b[0;32m   1054\u001b[0m )\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse_output:\n\u001b[1;32m-> 1056\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\u001b[38;5;241m.\u001b[39mtoarray()\n\u001b[0;32m   1057\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1058\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_compressed.py:1050\u001b[0m, in \u001b[0;36m_cs_matrix.toarray\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1048\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m order \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1049\u001b[0m     order \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_swap(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcf\u001b[39m\u001b[38;5;124m'\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 1050\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_toarray_args(order, out)\n\u001b[0;32m   1051\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mc_contiguous \u001b[38;5;129;01mor\u001b[39;00m out\u001b[38;5;241m.\u001b[39mflags\u001b[38;5;241m.\u001b[39mf_contiguous):\n\u001b[0;32m   1052\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mOutput array must be C or F contiguous\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\scipy\\sparse\\_base.py:1267\u001b[0m, in \u001b[0;36m_spbase._process_toarray_args\u001b[1;34m(self, order, out)\u001b[0m\n\u001b[0;32m   1265\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n\u001b[0;32m   1266\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1267\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mzeros(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, order\u001b[38;5;241m=\u001b[39morder)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.52 GiB for an array with shape (2000000, 639) and data type float64"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Encoding \"Sex\" as binary values\n",
    "encoder = LabelEncoder()\n",
    "df['Sex'] = encoder.fit_transform(df['Sex'])  # Male will be 1, Female will be 0\n",
    "\n",
    "# One-hot encoding \"Job Title\"\n",
    "onehot_encoder = OneHotEncoder(sparse=False)\n",
    "job_title_encoded = onehot_encoder.fit_transform(df['Job Title'].values.reshape(-1, 1))\n",
    "\n",
    "# Splitting the dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(job_title_encoded, df['Sex'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Building the model\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=X_train.shape[1], activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=5, verbose=1)\n",
    "\n",
    "# Evaluating the model\n",
    "loss, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Predict 'Sex' based on one-hot encoded job titles\n",
    "predicted_sex = model.predict(job_title_encoded)\n",
    "\n",
    "# Decode predicted 'Sex'\n",
    "predicted_sex_decoded = encoder.inverse_transform((predicted_sex > 0.5).astype(int).reshape(-1))\n",
    "\n",
    "# Add predicted 'Sex' to DataFrame\n",
    "df['Predicted Sex'] = predicted_sex_decoded\n",
    "\n",
    "# Display DataFrame with predicted 'Sex'\n",
    "print(df[['Job Title', 'Predicted Sex']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c70fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
